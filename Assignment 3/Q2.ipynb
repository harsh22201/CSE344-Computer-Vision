{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11473436,"sourceType":"datasetVersion","datasetId":7190544}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image\nimport requests\nimport torch\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\n\n# Load model and processor\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n\n# Load an image\nimage = Image.open(\"/kaggle/input/cv-assgn3/sample_image.jpg\").convert('RGB')\n\n# Ask a questions\nquestions = [\"Where is the dog present in the image?\",\n             \"Where is the man present in the image?\"]\n\nfor question in questions:\n    # Prepare inputs\n    inputs = processor(image, question, return_tensors=\"pt\").to(model.device)\n\n    # Generate answer\n    with torch.no_grad():\n        output_ids = model.generate(**inputs)\n        answer = processor.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n    print(f\"Q: {question}\")\n    print(f\"A: {answer}\")\n    print(\"-\" * 40)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T19:21:38.493308Z","iopub.execute_input":"2025-04-19T19:21:38.493683Z","iopub.status.idle":"2025-04-19T19:22:25.681025Z","shell.execute_reply.started":"2025-04-19T19:21:38.493653Z","shell.execute_reply":"2025-04-19T19:22:25.680213Z"}},"outputs":[{"name":"stderr","text":"2025-04-19 19:21:55.642460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745090515.898321      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745090515.968748      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeb91a329fea4ccaaffddb73b85146c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b77f5d3469c4cb2b56dd09de184f58f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cc0e5c673c64916945352a3efb1bb11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf4422b23574deaac598e951aee44a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ddf941922347839d9abe7263a0dc3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"990ffe2959764bb6830952a5832a8df2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89c033c77f42428492b1751abdf58162"}},"metadata":{}},{"name":"stdout","text":"Q: Where is the dog present in the image?\nA: in man ' s arms\n----------------------------------------\nQ: Where is the man present in the image?\nA: living room\n----------------------------------------\n","output_type":"stream"}],"execution_count":1}]}